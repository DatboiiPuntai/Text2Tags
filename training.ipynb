{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -q bitsandbytes datasets accelerate loralib sentencepiece\n",
    "!pip install tensorboardX\n",
    "!pip install -q git+https://github.com/huggingface/transformers.git git+https://github.com/huggingface/peft.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (None)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda117.dll\n",
      "CUDA SETUP: CUDA runtime path found: C:\\Users\\panta\\anaconda3\\envs\\nlp\\bin\\cudart64_110.dll\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda117.dll...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:152: UserWarning: C:\\Users\\panta\\anaconda3\\envs\\nlp did not contain ['cudart64_110.dll', 'cudart64_120.dll'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:152: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {WindowsPath('C:/Users/panta/anaconda3/envs/nlp/Library/usr/bin'), WindowsPath('C:/Users/panta/anaconda3/envs/nlp/Library/mingw-w64/bin')}\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM, AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_int8_training\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5f3d3655c540f0835247eb056f8479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/653 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\panta\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33b0946c800438eba925a7f46ec07fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/2.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9689b3897d1743f5b44d95206d0654b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc96210cccae48c2b2fd36a396ab3db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b6204fca3a47669b0c2da7247d3656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e7310cea3046cfa5237278e90f2f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a4e951b1f84cecb726a0a259fc4cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BASE_MODEL = \"facebook/opt-1.3b\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "\n",
    "tokenizer.pad_token_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3145728 || all params: 1318903808 || trainable%: 0.23851079820371554\n"
     ]
    }
   ],
   "source": [
    "model = prepare_model_for_int8_training(model)\n",
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sample(item, max_seq_length=1024, add_eos_token=True):\n",
    "        result = tokenizer(\n",
    "            item,\n",
    "            truncation=True,\n",
    "            max_length=max_seq_length,\n",
    "            padding=True,\n",
    "        )\n",
    "        result = {\n",
    "            \"input_ids\": result[\"input_ids\"][:-1],\n",
    "            \"attention_mask\": result[\"attention_mask\"][:-1],\n",
    "        }\n",
    "        if (\n",
    "            result[\"input_ids\"][-1] != tokenizer.eos_token_id\n",
    "            and len(result[\"input_ids\"]) < max_seq_length\n",
    "            and add_eos_token\n",
    "        ):\n",
    "            result[\"input_ids\"].append(tokenizer.eos_token_id)\n",
    "            result[\"attention_mask\"].append(1)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):\n",
    "    return f\"### Caption: {data_point['caption_string']}\\n### Tags:{data_point['tag_string']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/panta/.cache/huggingface/datasets/json/default-fac367448397b4f6/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fbd02ba027b44c1b96a1eca2ebe66e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81130defedc448789b652ff9817508df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18952 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00bb2ee21dc34786a48577565f2dfcba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/998 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['caption_string', 'tag_string', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 18952\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['caption_string', 'tag_string', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 998\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"json\", data_files=r'dataset/train_data.json')\n",
    "data = data[\"train\"].train_test_split(test_size=0.05, shuffle=True, seed=42)\n",
    "data = data.map(lambda x: tokenize_sample(generate_prompt(x)))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8847d8e92d3643938f44e5fb11385385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/444 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.947, 'learning_rate': 9.954954954954956e-05, 'epoch': 0.01}\n",
      "{'loss': 2.8607, 'learning_rate': 9.90990990990991e-05, 'epoch': 0.03}\n",
      "{'loss': 2.7888, 'learning_rate': 9.864864864864865e-05, 'epoch': 0.04}\n",
      "{'loss': 2.7105, 'learning_rate': 9.81981981981982e-05, 'epoch': 0.05}\n",
      "{'loss': 2.6408, 'learning_rate': 9.774774774774775e-05, 'epoch': 0.07}\n",
      "{'loss': 2.6105, 'learning_rate': 9.729729729729731e-05, 'epoch': 0.08}\n",
      "{'loss': 2.5864, 'learning_rate': 9.684684684684685e-05, 'epoch': 0.09}\n",
      "{'loss': 2.5305, 'learning_rate': 9.639639639639641e-05, 'epoch': 0.11}\n",
      "{'loss': 2.497, 'learning_rate': 9.594594594594595e-05, 'epoch': 0.12}\n",
      "{'loss': 2.4375, 'learning_rate': 9.54954954954955e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a335f29292042e5a4d108e0bd3ff6de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3455841541290283, 'eval_runtime': 104.7633, 'eval_samples_per_second': 9.526, 'eval_steps_per_second': 1.193, 'epoch': 0.14}\n",
      "{'loss': 2.4123, 'learning_rate': 9.504504504504504e-05, 'epoch': 0.15}\n",
      "{'loss': 2.4034, 'learning_rate': 9.45945945945946e-05, 'epoch': 0.16}\n",
      "{'loss': 2.3773, 'learning_rate': 9.414414414414416e-05, 'epoch': 0.18}\n",
      "{'loss': 2.3189, 'learning_rate': 9.36936936936937e-05, 'epoch': 0.19}\n",
      "{'loss': 2.333, 'learning_rate': 9.324324324324324e-05, 'epoch': 0.2}\n",
      "{'loss': 2.2993, 'learning_rate': 9.279279279279279e-05, 'epoch': 0.22}\n",
      "{'loss': 2.3056, 'learning_rate': 9.234234234234235e-05, 'epoch': 0.23}\n",
      "{'loss': 2.2725, 'learning_rate': 9.18918918918919e-05, 'epoch': 0.24}\n",
      "{'loss': 2.2531, 'learning_rate': 9.144144144144145e-05, 'epoch': 0.26}\n",
      "{'loss': 2.2582, 'learning_rate': 9.0990990990991e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf879dd4c1874b1088bc1b8ae002d499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1617355346679688, 'eval_runtime': 101.1269, 'eval_samples_per_second': 9.869, 'eval_steps_per_second': 1.236, 'epoch': 0.27}\n",
      "{'loss': 2.2082, 'learning_rate': 9.054054054054055e-05, 'epoch': 0.28}\n",
      "{'loss': 2.2291, 'learning_rate': 9.009009009009009e-05, 'epoch': 0.3}\n",
      "{'loss': 2.1921, 'learning_rate': 8.963963963963964e-05, 'epoch': 0.31}\n",
      "{'loss': 2.2023, 'learning_rate': 8.918918918918919e-05, 'epoch': 0.32}\n",
      "{'loss': 2.1642, 'learning_rate': 8.873873873873875e-05, 'epoch': 0.34}\n",
      "{'loss': 2.1594, 'learning_rate': 8.82882882882883e-05, 'epoch': 0.35}\n",
      "{'loss': 2.158, 'learning_rate': 8.783783783783784e-05, 'epoch': 0.36}\n",
      "{'loss': 2.1304, 'learning_rate': 8.738738738738738e-05, 'epoch': 0.38}\n",
      "{'loss': 2.1328, 'learning_rate': 8.693693693693694e-05, 'epoch': 0.39}\n",
      "{'loss': 2.1391, 'learning_rate': 8.64864864864865e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c27402baf90d4ba4a61c677049f4091d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.0586838722229004, 'eval_runtime': 100.6107, 'eval_samples_per_second': 9.919, 'eval_steps_per_second': 1.242, 'epoch': 0.41}\n",
      "{'loss': 2.1386, 'learning_rate': 8.603603603603604e-05, 'epoch': 0.42}\n",
      "{'loss': 2.1127, 'learning_rate': 8.55855855855856e-05, 'epoch': 0.43}\n",
      "{'loss': 2.1123, 'learning_rate': 8.513513513513514e-05, 'epoch': 0.45}\n",
      "{'loss': 2.0869, 'learning_rate': 8.468468468468469e-05, 'epoch': 0.46}\n",
      "{'loss': 2.1109, 'learning_rate': 8.423423423423423e-05, 'epoch': 0.47}\n",
      "{'loss': 2.1027, 'learning_rate': 8.378378378378379e-05, 'epoch': 0.49}\n",
      "{'loss': 2.1104, 'learning_rate': 8.333333333333334e-05, 'epoch': 0.5}\n",
      "{'loss': 2.0841, 'learning_rate': 8.288288288288289e-05, 'epoch': 0.51}\n",
      "{'loss': 2.0607, 'learning_rate': 8.243243243243243e-05, 'epoch': 0.53}\n",
      "{'loss': 2.0395, 'learning_rate': 8.198198198198198e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396037db01d346069f6f75620dae61d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9867099523544312, 'eval_runtime': 100.9585, 'eval_samples_per_second': 9.885, 'eval_steps_per_second': 1.238, 'epoch': 0.54}\n",
      "{'loss': 2.0433, 'learning_rate': 8.153153153153153e-05, 'epoch': 0.55}\n",
      "{'loss': 2.0505, 'learning_rate': 8.108108108108109e-05, 'epoch': 0.57}\n",
      "{'loss': 2.0624, 'learning_rate': 8.063063063063063e-05, 'epoch': 0.58}\n",
      "{'loss': 2.055, 'learning_rate': 8.018018018018019e-05, 'epoch': 0.59}\n",
      "{'loss': 2.0501, 'learning_rate': 7.972972972972974e-05, 'epoch': 0.61}\n",
      "{'loss': 2.023, 'learning_rate': 7.927927927927928e-05, 'epoch': 0.62}\n",
      "{'loss': 1.9981, 'learning_rate': 7.882882882882884e-05, 'epoch': 0.63}\n",
      "{'loss': 2.0263, 'learning_rate': 7.837837837837838e-05, 'epoch': 0.65}\n",
      "{'loss': 2.0083, 'learning_rate': 7.792792792792794e-05, 'epoch': 0.66}\n",
      "{'loss': 2.0071, 'learning_rate': 7.747747747747748e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbfd361541864881a5f303afc435cf4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9342427253723145, 'eval_runtime': 100.819, 'eval_samples_per_second': 9.899, 'eval_steps_per_second': 1.24, 'epoch': 0.68}\n",
      "{'loss': 1.9891, 'learning_rate': 7.702702702702703e-05, 'epoch': 0.69}\n",
      "{'loss': 2.0027, 'learning_rate': 7.657657657657657e-05, 'epoch': 0.7}\n",
      "{'loss': 1.9808, 'learning_rate': 7.612612612612613e-05, 'epoch': 0.72}\n",
      "{'loss': 1.9743, 'learning_rate': 7.567567567567568e-05, 'epoch': 0.73}\n",
      "{'loss': 1.9911, 'learning_rate': 7.522522522522523e-05, 'epoch': 0.74}\n",
      "{'loss': 1.9597, 'learning_rate': 7.477477477477479e-05, 'epoch': 0.76}\n",
      "{'loss': 1.995, 'learning_rate': 7.432432432432433e-05, 'epoch': 0.77}\n",
      "{'loss': 1.9862, 'learning_rate': 7.387387387387387e-05, 'epoch': 0.78}\n",
      "{'loss': 1.9798, 'learning_rate': 7.342342342342343e-05, 'epoch': 0.8}\n",
      "{'loss': 1.9518, 'learning_rate': 7.297297297297297e-05, 'epoch': 0.81}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f813d88392cd415c938238fc7bc9962c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8934754133224487, 'eval_runtime': 100.9971, 'eval_samples_per_second': 9.881, 'eval_steps_per_second': 1.238, 'epoch': 0.81}\n",
      "{'loss': 1.961, 'learning_rate': 7.252252252252253e-05, 'epoch': 0.82}\n",
      "{'loss': 1.9431, 'learning_rate': 7.207207207207208e-05, 'epoch': 0.84}\n",
      "{'loss': 1.9254, 'learning_rate': 7.162162162162162e-05, 'epoch': 0.85}\n",
      "{'loss': 1.9731, 'learning_rate': 7.117117117117116e-05, 'epoch': 0.86}\n",
      "{'loss': 1.9614, 'learning_rate': 7.072072072072072e-05, 'epoch': 0.88}\n",
      "{'loss': 1.9465, 'learning_rate': 7.027027027027028e-05, 'epoch': 0.89}\n",
      "{'loss': 1.9459, 'learning_rate': 6.981981981981982e-05, 'epoch': 0.91}\n",
      "{'loss': 1.9515, 'learning_rate': 6.936936936936938e-05, 'epoch': 0.92}\n",
      "{'loss': 1.9469, 'learning_rate': 6.891891891891892e-05, 'epoch': 0.93}\n",
      "{'loss': 1.9358, 'learning_rate': 6.846846846846847e-05, 'epoch': 0.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ed18b0ef484998864b13579b583e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8599344491958618, 'eval_runtime': 100.5666, 'eval_samples_per_second': 9.924, 'eval_steps_per_second': 1.243, 'epoch': 0.95}\n",
      "{'loss': 1.9256, 'learning_rate': 6.801801801801802e-05, 'epoch': 0.96}\n",
      "{'loss': 1.9222, 'learning_rate': 6.756756756756757e-05, 'epoch': 0.97}\n",
      "{'loss': 1.9226, 'learning_rate': 6.711711711711713e-05, 'epoch': 0.99}\n",
      "{'loss': 1.9402, 'learning_rate': 6.666666666666667e-05, 'epoch': 1.0}\n",
      "{'loss': 1.9127, 'learning_rate': 6.621621621621621e-05, 'epoch': 1.01}\n",
      "{'loss': 1.9051, 'learning_rate': 6.576576576576577e-05, 'epoch': 1.03}\n",
      "{'loss': 1.9493, 'learning_rate': 6.531531531531531e-05, 'epoch': 1.04}\n",
      "{'loss': 1.9155, 'learning_rate': 6.486486486486487e-05, 'epoch': 1.05}\n",
      "{'loss': 1.8901, 'learning_rate': 6.441441441441442e-05, 'epoch': 1.07}\n",
      "{'loss': 1.898, 'learning_rate': 6.396396396396397e-05, 'epoch': 1.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1bc52c072524d448903f686ee83c7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8337585926055908, 'eval_runtime': 100.3473, 'eval_samples_per_second': 9.945, 'eval_steps_per_second': 1.246, 'epoch': 1.08}\n",
      "{'loss': 1.9014, 'learning_rate': 6.351351351351352e-05, 'epoch': 1.09}\n",
      "{'loss': 1.8876, 'learning_rate': 6.306306306306306e-05, 'epoch': 1.11}\n",
      "{'loss': 1.9238, 'learning_rate': 6.261261261261262e-05, 'epoch': 1.12}\n",
      "{'loss': 1.8834, 'learning_rate': 6.216216216216216e-05, 'epoch': 1.13}\n",
      "{'loss': 1.8904, 'learning_rate': 6.171171171171172e-05, 'epoch': 1.15}\n",
      "{'loss': 1.8992, 'learning_rate': 6.126126126126126e-05, 'epoch': 1.16}\n",
      "{'loss': 1.9035, 'learning_rate': 6.0810810810810814e-05, 'epoch': 1.18}\n",
      "{'loss': 1.8877, 'learning_rate': 6.0360360360360365e-05, 'epoch': 1.19}\n",
      "{'loss': 1.8863, 'learning_rate': 5.990990990990991e-05, 'epoch': 1.2}\n",
      "{'loss': 1.8624, 'learning_rate': 5.9459459459459466e-05, 'epoch': 1.22}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f355d6ad6e8c4944b69b258e602be4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8116698265075684, 'eval_runtime': 100.4193, 'eval_samples_per_second': 9.938, 'eval_steps_per_second': 1.245, 'epoch': 1.22}\n",
      "{'loss': 1.873, 'learning_rate': 5.900900900900901e-05, 'epoch': 1.23}\n",
      "{'loss': 1.9186, 'learning_rate': 5.855855855855856e-05, 'epoch': 1.24}\n",
      "{'loss': 1.8298, 'learning_rate': 5.8108108108108105e-05, 'epoch': 1.26}\n",
      "{'loss': 1.8704, 'learning_rate': 5.765765765765766e-05, 'epoch': 1.27}\n",
      "{'loss': 1.8982, 'learning_rate': 5.720720720720721e-05, 'epoch': 1.28}\n",
      "{'loss': 1.841, 'learning_rate': 5.6756756756756757e-05, 'epoch': 1.3}\n",
      "{'loss': 1.8935, 'learning_rate': 5.6306306306306314e-05, 'epoch': 1.31}\n",
      "{'loss': 1.8707, 'learning_rate': 5.585585585585585e-05, 'epoch': 1.32}\n",
      "{'loss': 1.8604, 'learning_rate': 5.540540540540541e-05, 'epoch': 1.34}\n",
      "{'loss': 1.8577, 'learning_rate': 5.4954954954954966e-05, 'epoch': 1.35}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64fd19e6e5e47beaf0fb6de14f72d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.791964054107666, 'eval_runtime': 100.3477, 'eval_samples_per_second': 9.945, 'eval_steps_per_second': 1.246, 'epoch': 1.35}\n",
      "{'loss': 1.8695, 'learning_rate': 5.45045045045045e-05, 'epoch': 1.36}\n",
      "{'loss': 1.8644, 'learning_rate': 5.405405405405406e-05, 'epoch': 1.38}\n",
      "{'loss': 1.891, 'learning_rate': 5.3603603603603604e-05, 'epoch': 1.39}\n",
      "{'loss': 1.8857, 'learning_rate': 5.3153153153153155e-05, 'epoch': 1.4}\n",
      "{'loss': 1.8653, 'learning_rate': 5.27027027027027e-05, 'epoch': 1.42}\n",
      "{'loss': 1.8847, 'learning_rate': 5.2252252252252256e-05, 'epoch': 1.43}\n",
      "{'loss': 1.8593, 'learning_rate': 5.180180180180181e-05, 'epoch': 1.45}\n",
      "{'loss': 1.8348, 'learning_rate': 5.135135135135135e-05, 'epoch': 1.46}\n",
      "{'loss': 1.851, 'learning_rate': 5.090090090090091e-05, 'epoch': 1.47}\n",
      "{'loss': 1.8137, 'learning_rate': 5.0450450450450445e-05, 'epoch': 1.49}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adba19d7c4384a1b8935fcddd0347443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7783831357955933, 'eval_runtime': 100.3326, 'eval_samples_per_second': 9.947, 'eval_steps_per_second': 1.246, 'epoch': 1.49}\n",
      "{'loss': 1.8547, 'learning_rate': 5e-05, 'epoch': 1.5}\n",
      "{'loss': 1.8604, 'learning_rate': 4.954954954954955e-05, 'epoch': 1.51}\n",
      "{'loss': 1.8447, 'learning_rate': 4.90990990990991e-05, 'epoch': 1.53}\n",
      "{'loss': 1.8382, 'learning_rate': 4.8648648648648654e-05, 'epoch': 1.54}\n",
      "{'loss': 1.8314, 'learning_rate': 4.8198198198198205e-05, 'epoch': 1.55}\n",
      "{'loss': 1.8428, 'learning_rate': 4.774774774774775e-05, 'epoch': 1.57}\n",
      "{'loss': 1.8376, 'learning_rate': 4.72972972972973e-05, 'epoch': 1.58}\n",
      "{'loss': 1.8315, 'learning_rate': 4.684684684684685e-05, 'epoch': 1.59}\n",
      "{'loss': 1.8149, 'learning_rate': 4.6396396396396394e-05, 'epoch': 1.61}\n",
      "{'loss': 1.8251, 'learning_rate': 4.594594594594595e-05, 'epoch': 1.62}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f617666e027a4eb1b9734c9a005a5cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7639708518981934, 'eval_runtime': 100.2215, 'eval_samples_per_second': 9.958, 'eval_steps_per_second': 1.247, 'epoch': 1.62}\n",
      "{'loss': 1.8357, 'learning_rate': 4.54954954954955e-05, 'epoch': 1.63}\n",
      "{'loss': 1.8249, 'learning_rate': 4.5045045045045046e-05, 'epoch': 1.65}\n",
      "{'loss': 1.829, 'learning_rate': 4.4594594594594596e-05, 'epoch': 1.66}\n",
      "{'loss': 1.8286, 'learning_rate': 4.414414414414415e-05, 'epoch': 1.67}\n",
      "{'loss': 1.794, 'learning_rate': 4.369369369369369e-05, 'epoch': 1.69}\n",
      "{'loss': 1.8243, 'learning_rate': 4.324324324324325e-05, 'epoch': 1.7}\n",
      "{'loss': 1.8361, 'learning_rate': 4.27927927927928e-05, 'epoch': 1.72}\n",
      "{'loss': 1.826, 'learning_rate': 4.234234234234234e-05, 'epoch': 1.73}\n",
      "{'loss': 1.8468, 'learning_rate': 4.189189189189189e-05, 'epoch': 1.74}\n",
      "{'loss': 1.7842, 'learning_rate': 4.1441441441441444e-05, 'epoch': 1.76}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96631b179414acfac47aa339992960f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7517528533935547, 'eval_runtime': 100.1138, 'eval_samples_per_second': 9.969, 'eval_steps_per_second': 1.249, 'epoch': 1.76}\n",
      "{'loss': 1.8066, 'learning_rate': 4.099099099099099e-05, 'epoch': 1.77}\n",
      "{'loss': 1.8423, 'learning_rate': 4.0540540540540545e-05, 'epoch': 1.78}\n",
      "{'loss': 1.8157, 'learning_rate': 4.0090090090090096e-05, 'epoch': 1.8}\n",
      "{'loss': 1.8331, 'learning_rate': 3.963963963963964e-05, 'epoch': 1.81}\n",
      "{'loss': 1.8076, 'learning_rate': 3.918918918918919e-05, 'epoch': 1.82}\n",
      "{'loss': 1.7872, 'learning_rate': 3.873873873873874e-05, 'epoch': 1.84}\n",
      "{'loss': 1.8405, 'learning_rate': 3.8288288288288285e-05, 'epoch': 1.85}\n",
      "{'loss': 1.8053, 'learning_rate': 3.783783783783784e-05, 'epoch': 1.86}\n",
      "{'loss': 1.8239, 'learning_rate': 3.738738738738739e-05, 'epoch': 1.88}\n",
      "{'loss': 1.7898, 'learning_rate': 3.693693693693694e-05, 'epoch': 1.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f2486d1c084fb9944b91302fe38e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7429043054580688, 'eval_runtime': 100.3196, 'eval_samples_per_second': 9.948, 'eval_steps_per_second': 1.246, 'epoch': 1.89}\n",
      "{'loss': 1.7929, 'learning_rate': 3.648648648648649e-05, 'epoch': 1.9}\n",
      "{'loss': 1.7915, 'learning_rate': 3.603603603603604e-05, 'epoch': 1.92}\n",
      "{'loss': 1.8217, 'learning_rate': 3.558558558558558e-05, 'epoch': 1.93}\n",
      "{'loss': 1.8336, 'learning_rate': 3.513513513513514e-05, 'epoch': 1.95}\n",
      "{'loss': 1.8223, 'learning_rate': 3.468468468468469e-05, 'epoch': 1.96}\n",
      "{'loss': 1.8145, 'learning_rate': 3.4234234234234234e-05, 'epoch': 1.97}\n",
      "{'loss': 1.7922, 'learning_rate': 3.3783783783783784e-05, 'epoch': 1.99}\n",
      "{'loss': 1.7908, 'learning_rate': 3.3333333333333335e-05, 'epoch': 2.0}\n",
      "{'loss': 1.7979, 'learning_rate': 3.2882882882882886e-05, 'epoch': 2.01}\n",
      "{'loss': 1.8365, 'learning_rate': 3.2432432432432436e-05, 'epoch': 2.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6122aecbd648462a91e0c1a4f59e9bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7346677780151367, 'eval_runtime': 100.3273, 'eval_samples_per_second': 9.947, 'eval_steps_per_second': 1.246, 'epoch': 2.03}\n",
      "{'loss': 1.8191, 'learning_rate': 3.198198198198199e-05, 'epoch': 2.04}\n",
      "{'loss': 1.8316, 'learning_rate': 3.153153153153153e-05, 'epoch': 2.05}\n",
      "{'loss': 1.7977, 'learning_rate': 3.108108108108108e-05, 'epoch': 2.07}\n",
      "{'loss': 1.8015, 'learning_rate': 3.063063063063063e-05, 'epoch': 2.08}\n",
      "{'loss': 1.793, 'learning_rate': 3.0180180180180183e-05, 'epoch': 2.09}\n",
      "{'loss': 1.8146, 'learning_rate': 2.9729729729729733e-05, 'epoch': 2.11}\n",
      "{'loss': 1.7792, 'learning_rate': 2.927927927927928e-05, 'epoch': 2.12}\n",
      "{'loss': 1.7924, 'learning_rate': 2.882882882882883e-05, 'epoch': 2.13}\n",
      "{'loss': 1.7812, 'learning_rate': 2.8378378378378378e-05, 'epoch': 2.15}\n",
      "{'loss': 1.7891, 'learning_rate': 2.7927927927927926e-05, 'epoch': 2.16}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f5bd1f602a468e9cfc8365bb26b6d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7275221347808838, 'eval_runtime': 100.1456, 'eval_samples_per_second': 9.965, 'eval_steps_per_second': 1.248, 'epoch': 2.16}\n",
      "{'loss': 1.7909, 'learning_rate': 2.7477477477477483e-05, 'epoch': 2.17}\n",
      "{'loss': 1.7794, 'learning_rate': 2.702702702702703e-05, 'epoch': 2.19}\n",
      "{'loss': 1.8029, 'learning_rate': 2.6576576576576577e-05, 'epoch': 2.2}\n",
      "{'loss': 1.8072, 'learning_rate': 2.6126126126126128e-05, 'epoch': 2.22}\n",
      "{'loss': 1.7777, 'learning_rate': 2.5675675675675675e-05, 'epoch': 2.23}\n",
      "{'loss': 1.8009, 'learning_rate': 2.5225225225225222e-05, 'epoch': 2.24}\n",
      "{'loss': 1.7855, 'learning_rate': 2.4774774774774777e-05, 'epoch': 2.26}\n",
      "{'loss': 1.7991, 'learning_rate': 2.4324324324324327e-05, 'epoch': 2.27}\n",
      "{'loss': 1.781, 'learning_rate': 2.3873873873873874e-05, 'epoch': 2.28}\n",
      "{'loss': 1.7959, 'learning_rate': 2.3423423423423425e-05, 'epoch': 2.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e768ae0884014717b808e249fdffd938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7227169275283813, 'eval_runtime': 100.0525, 'eval_samples_per_second': 9.975, 'eval_steps_per_second': 1.249, 'epoch': 2.3}\n",
      "{'loss': 1.7841, 'learning_rate': 2.2972972972972976e-05, 'epoch': 2.31}\n",
      "{'loss': 1.7747, 'learning_rate': 2.2522522522522523e-05, 'epoch': 2.32}\n",
      "{'loss': 1.7716, 'learning_rate': 2.2072072072072073e-05, 'epoch': 2.34}\n",
      "{'loss': 1.7745, 'learning_rate': 2.1621621621621624e-05, 'epoch': 2.35}\n",
      "{'loss': 1.7952, 'learning_rate': 2.117117117117117e-05, 'epoch': 2.36}\n",
      "{'loss': 1.7691, 'learning_rate': 2.0720720720720722e-05, 'epoch': 2.38}\n",
      "{'loss': 1.781, 'learning_rate': 2.0270270270270273e-05, 'epoch': 2.39}\n",
      "{'loss': 1.7814, 'learning_rate': 1.981981981981982e-05, 'epoch': 2.4}\n",
      "{'loss': 1.7773, 'learning_rate': 1.936936936936937e-05, 'epoch': 2.42}\n",
      "{'loss': 1.771, 'learning_rate': 1.891891891891892e-05, 'epoch': 2.43}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2b5a97b75745d89dc51780cb132d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7160649299621582, 'eval_runtime': 100.2683, 'eval_samples_per_second': 9.953, 'eval_steps_per_second': 1.247, 'epoch': 2.43}\n",
      "{'loss': 1.7956, 'learning_rate': 1.846846846846847e-05, 'epoch': 2.44}\n",
      "{'loss': 1.7911, 'learning_rate': 1.801801801801802e-05, 'epoch': 2.46}\n",
      "{'loss': 1.7619, 'learning_rate': 1.756756756756757e-05, 'epoch': 2.47}\n",
      "{'loss': 1.7733, 'learning_rate': 1.7117117117117117e-05, 'epoch': 2.49}\n",
      "{'loss': 1.7941, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.5}\n",
      "{'loss': 1.7526, 'learning_rate': 1.6216216216216218e-05, 'epoch': 2.51}\n",
      "{'loss': 1.8033, 'learning_rate': 1.5765765765765765e-05, 'epoch': 2.53}\n",
      "{'loss': 1.77, 'learning_rate': 1.5315315315315316e-05, 'epoch': 2.54}\n",
      "{'loss': 1.8056, 'learning_rate': 1.4864864864864867e-05, 'epoch': 2.55}\n",
      "{'loss': 1.814, 'learning_rate': 1.4414414414414416e-05, 'epoch': 2.57}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18819cb563a44fd7a3d4745cc0615f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.714399814605713, 'eval_runtime': 100.3925, 'eval_samples_per_second': 9.941, 'eval_steps_per_second': 1.245, 'epoch': 2.57}\n",
      "{'loss': 1.7587, 'learning_rate': 1.3963963963963963e-05, 'epoch': 2.58}\n",
      "{'loss': 1.7775, 'learning_rate': 1.3513513513513515e-05, 'epoch': 2.59}\n",
      "{'loss': 1.7958, 'learning_rate': 1.3063063063063064e-05, 'epoch': 2.61}\n",
      "{'loss': 1.7843, 'learning_rate': 1.2612612612612611e-05, 'epoch': 2.62}\n",
      "{'loss': 1.8056, 'learning_rate': 1.2162162162162164e-05, 'epoch': 2.63}\n",
      "{'loss': 1.7794, 'learning_rate': 1.1711711711711713e-05, 'epoch': 2.65}\n",
      "{'loss': 1.7884, 'learning_rate': 1.1261261261261261e-05, 'epoch': 2.66}\n",
      "{'loss': 1.8102, 'learning_rate': 1.0810810810810812e-05, 'epoch': 2.67}\n",
      "{'loss': 1.7801, 'learning_rate': 1.0360360360360361e-05, 'epoch': 2.69}\n",
      "{'loss': 1.7451, 'learning_rate': 9.90990990990991e-06, 'epoch': 2.7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccbbdf42270c4d2f9c254a5e8c370138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7109984159469604, 'eval_runtime': 100.1298, 'eval_samples_per_second': 9.967, 'eval_steps_per_second': 1.248, 'epoch': 2.7}\n",
      "{'loss': 1.7816, 'learning_rate': 9.45945945945946e-06, 'epoch': 2.72}\n",
      "{'loss': 1.77, 'learning_rate': 9.00900900900901e-06, 'epoch': 2.73}\n",
      "{'loss': 1.7602, 'learning_rate': 8.558558558558558e-06, 'epoch': 2.74}\n",
      "{'loss': 1.7556, 'learning_rate': 8.108108108108109e-06, 'epoch': 2.76}\n",
      "{'loss': 1.7718, 'learning_rate': 7.657657657657658e-06, 'epoch': 2.77}\n",
      "{'loss': 1.7943, 'learning_rate': 7.207207207207208e-06, 'epoch': 2.78}\n",
      "{'loss': 1.7744, 'learning_rate': 6.7567567567567575e-06, 'epoch': 2.8}\n",
      "{'loss': 1.78, 'learning_rate': 6.306306306306306e-06, 'epoch': 2.81}\n",
      "{'loss': 1.801, 'learning_rate': 5.855855855855856e-06, 'epoch': 2.82}\n",
      "{'loss': 1.779, 'learning_rate': 5.405405405405406e-06, 'epoch': 2.84}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a096b7e6474a148a40bf802e6ae916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7086883783340454, 'eval_runtime': 100.1237, 'eval_samples_per_second': 9.968, 'eval_steps_per_second': 1.248, 'epoch': 2.84}\n",
      "{'loss': 1.7742, 'learning_rate': 4.954954954954955e-06, 'epoch': 2.85}\n",
      "{'loss': 1.7731, 'learning_rate': 4.504504504504505e-06, 'epoch': 2.86}\n",
      "{'loss': 1.774, 'learning_rate': 4.0540540540540545e-06, 'epoch': 2.88}\n",
      "{'loss': 1.8027, 'learning_rate': 3.603603603603604e-06, 'epoch': 2.89}\n",
      "{'loss': 1.7832, 'learning_rate': 3.153153153153153e-06, 'epoch': 2.9}\n",
      "{'loss': 1.7615, 'learning_rate': 2.702702702702703e-06, 'epoch': 2.92}\n",
      "{'loss': 1.766, 'learning_rate': 2.2522522522522524e-06, 'epoch': 2.93}\n",
      "{'loss': 1.7645, 'learning_rate': 1.801801801801802e-06, 'epoch': 2.94}\n",
      "{'loss': 1.7731, 'learning_rate': 1.3513513513513515e-06, 'epoch': 2.96}\n",
      "{'loss': 1.7934, 'learning_rate': 9.00900900900901e-07, 'epoch': 2.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61922b00d34b462aa2c0339b48cb203f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.708711862564087, 'eval_runtime': 101.33, 'eval_samples_per_second': 9.849, 'eval_steps_per_second': 1.234, 'epoch': 2.97}\n",
      "{'loss': 1.7675, 'learning_rate': 4.504504504504505e-07, 'epoch': 2.99}\n",
      "{'loss': 1.7676, 'learning_rate': 0.0, 'epoch': 3.0}\n",
      "{'train_runtime': 28375.0387, 'train_samples_per_second': 2.004, 'train_steps_per_second': 0.016, 'train_loss': 1.9319579338168238, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=444, training_loss=1.9319579338168238, metrics={'train_runtime': 28375.0387, 'train_samples_per_second': 2.004, 'train_steps_per_second': 0.016, 'train_loss': 1.9319579338168238, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model=model, \n",
    "    train_dataset=data['train'],\n",
    "    eval_dataset=data['test'],\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=4, \n",
    "        gradient_accumulation_steps=32,\n",
    "        num_train_epochs=3,\n",
    "        learning_rate=1e-4, \n",
    "        fp16=True,\n",
    "        logging_steps=2,\n",
    "        optim=\"adamw_torch\",\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=20,\n",
    "        output_dir='outputs',\n",
    "#         save_strategy=\"steps\",\n",
    "#         save_steps=20,\n",
    "#         save_total_limit=2,\n",
    "        report_to=\"tensorboard\"\n",
    "    ),\n",
    ")\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\utils\\checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ### Caption: Eromame's art features a female Corrin and Incineroar in armor from Fire Emblem, with long hair, a hairband, pointy ears, and an open mouth, against a simple background, and posted on their Twitter.\n",
      "### Tags:1girl, armor, fire_emblem, fire_emblem_femme_corrin, incineroar, long_hair, pointy_ears, point_of_view, twitter,\n"
     ]
    }
   ],
   "source": [
    "batch = tokenizer(\"### Caption: Eromame's art features a female Corrin and Incineroar in armor from Fire Emblem, with long hair, a hairband, pointy ears, and an open mouth, against a simple background, and posted on their Twitter.\", return_tensors='pt').to(\"cuda\")\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "  output_tokens = model.generate(**batch, max_new_tokens=300)\n",
    "\n",
    "print('\\n\\n', tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid.\n",
      "Your token has been saved in your configured git credential helpers (manager).\n",
      "Your token has been saved to C:\\Users\\panta\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48dd747820e74b8a957133740933eaba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd46429f5224a88b9668dc3c4fc8e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.bin:   0%|          | 0.00/12.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ooferdoodles/text2tags-opt-1.3b/commit/8f57a538dc7425fb94694cd2c5df16bf0f08eec8', commit_message='Upload model', commit_description='', oid='8f57a538dc7425fb94694cd2c5df16bf0f08eec8', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"ooferdoodles/text2tags-opt-1.3b\", use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(r\"loras/tagger-v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
