{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q bitsandbytes datasets accelerate loralib editdistance sentencepiece\n",
    "!pip install -q git+https://github.com/huggingface/transformers.git@main git+https://github.com/huggingface/peft.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (None)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda117.dll\n",
      "CUDA SETUP: CUDA runtime path found: C:\\Users\\panta\\anaconda3\\envs\\nlp\\bin\\cudart64_110.dll\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda117.dll...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:152: UserWarning: C:\\Users\\panta\\anaconda3\\envs\\nlp did not contain ['cudart64_110.dll', 'cudart64_120.dll'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:152: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {WindowsPath('C:/Users/panta/anaconda3/envs/nlp/Library/usr/bin'), WindowsPath('C:/Users/panta/anaconda3/envs/nlp/Library/mingw-w64/bin')}\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, LlamaTokenizer, LlamaForCausalLM, pipeline\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from llama_cpp import Llama\n",
    "from utils import similar_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTConfig {\n",
       "  \"_name_or_path\": \"facebook/opt-350m\",\n",
       "  \"_remove_final_layer_norm\": false,\n",
       "  \"activation_dropout\": 0.0,\n",
       "  \"activation_function\": \"relu\",\n",
       "  \"architectures\": [\n",
       "    \"OPTForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 2,\n",
       "  \"do_layer_norm_before\": false,\n",
       "  \"dropout\": 0.1,\n",
       "  \"enable_bias\": true,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"ffn_dim\": 4096,\n",
       "  \"hidden_size\": 1024,\n",
       "  \"init_std\": 0.02,\n",
       "  \"layer_norm_elementwise_affine\": true,\n",
       "  \"layerdrop\": 0.0,\n",
       "  \"max_position_embeddings\": 2048,\n",
       "  \"model_type\": \"opt\",\n",
       "  \"num_attention_heads\": 16,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"prefix\": \"</s>\",\n",
       "  \"quantization_config\": {\n",
       "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
       "    \"llm_int8_skip_modules\": null,\n",
       "    \"llm_int8_threshold\": 6.0,\n",
       "    \"load_in_8bit\": true\n",
       "  },\n",
       "  \"torch_dtype\": \"float16\",\n",
       "  \"transformers_version\": \"4.29.0.dev0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50272,\n",
       "  \"word_embed_proj_dim\": 512\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "peft_model_id = r\"ooferdoodles/text2tags-opt-350m\"\n",
    "base_model = \"facebook/opt-350m\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    return_dict=True,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "\n",
    "model = PeftModel.from_pretrained(model, peft_model_id, torch_dtype=torch.float16)\n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to C:/Users/panta/.cache/huggingface/datasets/json/default-6f40fc64f49b363b/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a880197699a34c70b8bf832c42b3b9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6396f63bc54749259febd0226aea4f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20af7882d06a452c847d3113c6312438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to C:/Users/panta/.cache/huggingface/datasets/json/default-6f40fc64f49b363b/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ac2031e4014ccbabcffe9a1f684569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['caption_string', 'tag_string'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset(\"json\", data_files=r\"dataset/test_data.json\")\n",
    "tag_dict = similar_tag.load_dict()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    temperature=1,\n",
    "    top_p=1,\n",
    "    top_k=40,\n",
    "    num_beams=4,\n",
    "    typical_p=1,\n",
    "    do_sample=True,\n",
    "    max_new_tokens=300,\n",
    "    use_cache=True,\n",
    "    no_repeat_ngram_size=3,\n",
    "    # pad_token_id=model.config.eos_token_id\n",
    "    # truncation_length=2048,\n",
    "    # min_length=0,\n",
    "    # add_bos_token=True,\n",
    "    # ban_eos_token=False,\n",
    "    # skip_special_tokens=True,\n",
    "    # stopping_strings=[],\n",
    "    # penalty_alpha=0,\n",
    "    # repetition_penalty=2.5,\n",
    "    # encoder_repetition_penalty=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe(data_point):\n",
    "    # max_new_tokens = int(len(data_point['caption_string']) * max_token_scale)\n",
    "    prompt = f\"### Caption: {data_point['caption_string']}\\n### Tags: \"\n",
    "    tokenized_prompt = tokenizer(\n",
    "        prompt, \n",
    "        return_tensors='pt', \n",
    "        add_special_tokens=True).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_tokens = model.generate(\n",
    "            input_ids=tokenized_prompt['input_ids'],\n",
    "            generation_config=generation_config,\n",
    "        )[0]\n",
    "    preds = tokenizer.decode(output_tokens, skip_special_tokens=True)\n",
    "    data_point['raw_preds'] = preds\n",
    "    pred_list = [x.strip() for x in preds.split('### Tags:')[-1].split(\",\")]\n",
    "    corrected_tags = similar_tag.correct_tags(pred_list, tag_dict)\n",
    "    data_point['tags'] = data_point['tag_string'].split(', ')\n",
    "    data_point['pred_tags'] = corrected_tags\n",
    "    return data_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "llm = Llama(model_path=r\"models\\ggml\\tagger-7b\\ggml-model-q4_2.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for llama cpp\n",
    "def pipe(data_point):\n",
    "    prompt = f\"### Caption: {data_point['caption_string']}\\n### Tags: \"\n",
    "    output = llm(prompt, max_tokens=100, stop=[\"### Tags:\", \"\\n\"], echo=True)\n",
    "    preds = output['choices'][0]['text']\n",
    "    data_point['raw_preds'] = preds\n",
    "    pred_list = [x.strip() for x in preds.split('### Tags:')[-1].split(\",\")]\n",
    "    corrected_tags = similar_tag.correct_tags(pred_list, tag_dict)\n",
    "    data_point['tags'] = data_point['tag_string'].split(', ')\n",
    "    data_point['pred_tags'] = corrected_tags\n",
    "    return data_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0fbe1ab5604631b4ae4f7a7a388898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_data = data.map(pipe)\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_point):\n",
    "    correct_count = len(set(data_point['tags']).intersection(data_point['pred_tags']))\n",
    "    # incorrect_count = len(data_point['tags']) - correct_count\n",
    "    data_point['accuracy'] = correct_count / len(data_point['tags']) * 100\n",
    "    return data_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluated_data = processed_data.map(evaluate_accuracy)\n",
    "evaluated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = evaluated_data['train'].to_pandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ogey = pipe(data['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1girl', 'breasts', 'closed_mouth', 'gloves', 'horns', 'large_breasts', 'long_hair', 'looking_at_viewer', 'monochrome', 'simple_background', 'smile', 'solo', 'star_ocean', 'star_ocean_anamnesis', 'star_ocean_till_the_end_of_time', 'white_background', 'wings']\n",
      "### Caption: With her mesmerizing gaze and ethereal wings, Clair Lasbard, from the Star Ocean franchise, comes to life in monochrome hues thanks to the exquisite artistry of kiikii_(kitsukedokoro). Her alluring smile and intricate horns, complemented by her long hair and gloves, make for a stunning portrayal of this character known for her large breasts. Amidst a simple white background, this piece captures the beauty and mystique of Clair, leaving us entranced by her presence.\n",
      "### Tags: 〈, :d, :o, blonde_hair, black_legs, blue_eyes, breasts, gloves, breasts_clair_lasbard, hair_ornament, hairband, hairclip, hairornament_gloves, large_breasts, looking_at_viewer, multiple_girls, star_ocean_(series), white_background, white_\n"
     ]
    }
   ],
   "source": [
    "print(ogey['tags'])\n",
    "print(ogey['raw_preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
