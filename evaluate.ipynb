{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q bitsandbytes datasets accelerate loralib editdistance sentencepiece\n",
    "!pip install -q git+https://github.com/huggingface/transformers.git@main git+https://github.com/huggingface/peft.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (None)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda117.dll\n",
      "CUDA SETUP: CUDA runtime path found: C:\\Users\\panta\\anaconda3\\envs\\nlp\\bin\\cudart64_110.dll\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda117.dll...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:152: UserWarning: C:\\Users\\panta\\anaconda3\\envs\\nlp did not contain ['cudart64_110.dll', 'cudart64_120.dll'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:152: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {WindowsPath('C:/Users/panta/anaconda3/envs/nlp/Library/mingw-w64/bin'), WindowsPath('C:/Users/panta/anaconda3/envs/nlp/Library/usr/bin')}\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, LlamaTokenizer, LlamaForCausalLM, pipeline\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from utils import similar_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTConfig {\n",
       "  \"_name_or_path\": \"facebook/opt-350m\",\n",
       "  \"_remove_final_layer_norm\": false,\n",
       "  \"activation_dropout\": 0.0,\n",
       "  \"activation_function\": \"relu\",\n",
       "  \"architectures\": [\n",
       "    \"OPTForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 2,\n",
       "  \"do_layer_norm_before\": false,\n",
       "  \"dropout\": 0.1,\n",
       "  \"enable_bias\": true,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"ffn_dim\": 4096,\n",
       "  \"hidden_size\": 1024,\n",
       "  \"init_std\": 0.02,\n",
       "  \"layer_norm_elementwise_affine\": true,\n",
       "  \"layerdrop\": 0.0,\n",
       "  \"max_position_embeddings\": 2048,\n",
       "  \"model_type\": \"opt\",\n",
       "  \"num_attention_heads\": 16,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"prefix\": \"</s>\",\n",
       "  \"quantization_config\": {\n",
       "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
       "    \"llm_int8_skip_modules\": null,\n",
       "    \"llm_int8_threshold\": 6.0,\n",
       "    \"load_in_8bit\": true\n",
       "  },\n",
       "  \"torch_dtype\": \"float16\",\n",
       "  \"transformers_version\": \"4.29.0.dev0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50272,\n",
       "  \"word_embed_proj_dim\": 512\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "peft_model_id = r\"ooferdoodles/text2tags-opt-350m\"\n",
    "base_model = \"facebook/opt-350m\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    return_dict=True,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "\n",
    "model = PeftModel.from_pretrained(model, peft_model_id, torch_dtype=torch.float16)\n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/panta/.cache/huggingface/datasets/json/default-5cff6cb24ab66f93/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc6594d7bdb491fa6835932082ee198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['caption_string', 'tag_string'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset(\"json\", data_files=r\"dataset/test_data.json\")\n",
    "tag_dict = similar_tag.load_dict()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    temperature=1,\n",
    "    top_p=1,\n",
    "    top_k=40,\n",
    "    num_beams=4,\n",
    "    typical_p=1,\n",
    "    do_sample=True,\n",
    "    max_new_tokens=300,\n",
    "    use_cache=True,\n",
    "    no_repeat_ngram_size=3,\n",
    "    # pad_token_id=model.config.eos_token_id\n",
    "    # truncation_length=2048,\n",
    "    # min_length=0,\n",
    "    # add_bos_token=True,\n",
    "    # ban_eos_token=False,\n",
    "    # skip_special_tokens=True,\n",
    "    # stopping_strings=[],\n",
    "    # penalty_alpha=0,\n",
    "    # repetition_penalty=2.5,\n",
    "    # encoder_repetition_penalty=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe(data_point):\n",
    "    # max_new_tokens = int(len(data_point['caption_string']) * max_token_scale)\n",
    "    prompt = f\"### Caption: {data_point['caption_string']}\\n### Tags: \"\n",
    "    tokenized_prompt = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "    \n",
    "    output_tokens = model.generate(\n",
    "        input_ids=tokenized_prompt['input_ids'],\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "    preds = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "    pred_list = [x.strip() for x in preds.split('### Tags:')[-1].split(\",\")]\n",
    "    corrected_tags = similar_tag.correct_tags(pred_list, tag_dict)\n",
    "    data_point['tags'] = data_point['tag_string'].split(', ')\n",
    "    data_point['pred_tags'] = corrected_tags\n",
    "    return data_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0725ce6ee1e04c3d913b4977a48481f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['caption_string', 'tag_string', 'tags', 'pred_tags'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data = data.map(pipe)\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_point):\n",
    "    correct_count = len(set(data_point['tags']).intersection(data_point['pred_tags']))\n",
    "    # incorrect_count = len(data_point['tags']) - correct_count\n",
    "    data_point['accuracy'] = correct_count / len(data_point['tags']) * 100\n",
    "    return data_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1d46db4bc24ce887caf7c3e3c233e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['caption_string', 'tag_string', 'tags', 'pred_tags', 'accuracy'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluated_data = processed_data.map(evaluate_accuracy)\n",
    "evaluated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption_string</th>\n",
       "      <th>tag_string</th>\n",
       "      <th>tags</th>\n",
       "      <th>pred_tags</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>With her mesmerizing gaze and ethereal wings, ...</td>\n",
       "      <td>1girl, breasts, closed_mouth, gloves, horns, l...</td>\n",
       "      <td>[1girl, breasts, closed_mouth, gloves, horns, ...</td>\n",
       "      <td>[:d, :o, black_hair, blue_eyes, braid, breasts...</td>\n",
       "      <td>23.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kisaragi Ai's art features Garma Zabi from Gun...</td>\n",
       "      <td>1boy, adjusting_hair, bow, bowtie, brown_eyes,...</td>\n",
       "      <td>[1boy, adjusting_hair, bow, bowtie, brown_eyes...</td>\n",
       "      <td>[!!, bangs, blonde_hair, bow, brown_eyes, dres...</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rojer18's art depicts Oozora Hiro from Danball...</td>\n",
       "      <td>1boy, ahoge, belt, blue_hair, closed_mouth, cr...</td>\n",
       "      <td>[1boy, ahoge, belt, blue_hair, closed_mouth, c...</td>\n",
       "      <td>[bag, black_hair, black_skirt, blue_eyes, can,...</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amidst the chaos of Danganronpa, Criis-chan ca...</td>\n",
       "      <td>2girls, :d, ahoge, arm_up, bangs, black_shirt,...</td>\n",
       "      <td>[2girls, :d, ahoge, arm_up, bangs, black_shirt...</td>\n",
       "      <td>[bangs, black_hair, blue_eyes, blush, breasts,...</td>\n",
       "      <td>16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The artwork is a solo depiction of the charact...</td>\n",
       "      <td>1boy, ^_^, ahoge, blush, closed_eyes, fate/gra...</td>\n",
       "      <td>[1boy, ^_^, ahoge, blush, closed_eyes, fate/gr...</td>\n",
       "      <td>[:/, :d, :o, blush, braided_ponytail, closed_e...</td>\n",
       "      <td>47.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>The artwork features the character Bokuto Kout...</td>\n",
       "      <td>1boy, artist_name, bangs, black_shirt, collarb...</td>\n",
       "      <td>[1boy, artist_name, bangs, black_shirt, collar...</td>\n",
       "      <td>[!!, :d, blue_hair, brown_eyes, collared_shirt...</td>\n",
       "      <td>13.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>\"Too_mizuguchi's artwork portrays Oswald Chest...</td>\n",
       "      <td>1boy, bags_under_eyes, batman_(series), black_...</td>\n",
       "      <td>[1boy, bags_under_eyes, batman_(series), black...</td>\n",
       "      <td>[bag, bags_under_eyes, black_hair, blue_eyes, ...</td>\n",
       "      <td>41.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Denjinq's artistic prowess comes to life with ...</td>\n",
       "      <td>1boy, 5girls, aqua_hair, ass, bangs, black_hai...</td>\n",
       "      <td>[1boy, 5girls, aqua_hair, ass, bangs, black_ha...</td>\n",
       "      <td>[5girls, aqua_hair, black_eyes, blue_eyes, blu...</td>\n",
       "      <td>29.629630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>The artwork features a single female character...</td>\n",
       "      <td>1girl, :o, bangs, black_shirt, boots, bronya_z...</td>\n",
       "      <td>[1girl, :o, bangs, black_shirt, boots, bronya_...</td>\n",
       "      <td>[:d, :o, arrow_(projectile), black_shirt, blon...</td>\n",
       "      <td>27.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>With her charming smile and captivating gaze, ...</td>\n",
       "      <td>1girl, bangs, blue_eyes, blush, breasts, chibi...</td>\n",
       "      <td>[1girl, bangs, blue_eyes, blush, breasts, chib...</td>\n",
       "      <td>[blonde_hair, blush, breasts, chibi, eyebrows_...</td>\n",
       "      <td>61.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        caption_string   \n",
       "0    With her mesmerizing gaze and ethereal wings, ...  \\\n",
       "1    Kisaragi Ai's art features Garma Zabi from Gun...   \n",
       "2    Rojer18's art depicts Oozora Hiro from Danball...   \n",
       "3    Amidst the chaos of Danganronpa, Criis-chan ca...   \n",
       "4    The artwork is a solo depiction of the charact...   \n",
       "..                                                 ...   \n",
       "145  The artwork features the character Bokuto Kout...   \n",
       "146  \"Too_mizuguchi's artwork portrays Oswald Chest...   \n",
       "147  Denjinq's artistic prowess comes to life with ...   \n",
       "148  The artwork features a single female character...   \n",
       "149  With her charming smile and captivating gaze, ...   \n",
       "\n",
       "                                            tag_string   \n",
       "0    1girl, breasts, closed_mouth, gloves, horns, l...  \\\n",
       "1    1boy, adjusting_hair, bow, bowtie, brown_eyes,...   \n",
       "2    1boy, ahoge, belt, blue_hair, closed_mouth, cr...   \n",
       "3    2girls, :d, ahoge, arm_up, bangs, black_shirt,...   \n",
       "4    1boy, ^_^, ahoge, blush, closed_eyes, fate/gra...   \n",
       "..                                                 ...   \n",
       "145  1boy, artist_name, bangs, black_shirt, collarb...   \n",
       "146  1boy, bags_under_eyes, batman_(series), black_...   \n",
       "147  1boy, 5girls, aqua_hair, ass, bangs, black_hai...   \n",
       "148  1girl, :o, bangs, black_shirt, boots, bronya_z...   \n",
       "149  1girl, bangs, blue_eyes, blush, breasts, chibi...   \n",
       "\n",
       "                                                  tags   \n",
       "0    [1girl, breasts, closed_mouth, gloves, horns, ...  \\\n",
       "1    [1boy, adjusting_hair, bow, bowtie, brown_eyes...   \n",
       "2    [1boy, ahoge, belt, blue_hair, closed_mouth, c...   \n",
       "3    [2girls, :d, ahoge, arm_up, bangs, black_shirt...   \n",
       "4    [1boy, ^_^, ahoge, blush, closed_eyes, fate/gr...   \n",
       "..                                                 ...   \n",
       "145  [1boy, artist_name, bangs, black_shirt, collar...   \n",
       "146  [1boy, bags_under_eyes, batman_(series), black...   \n",
       "147  [1boy, 5girls, aqua_hair, ass, bangs, black_ha...   \n",
       "148  [1girl, :o, bangs, black_shirt, boots, bronya_...   \n",
       "149  [1girl, bangs, blue_eyes, blush, breasts, chib...   \n",
       "\n",
       "                                             pred_tags   accuracy  \n",
       "0    [:d, :o, black_hair, blue_eyes, braid, breasts...  23.529412  \n",
       "1    [!!, bangs, blonde_hair, bow, brown_eyes, dres...  33.333333  \n",
       "2    [bag, black_hair, black_skirt, blue_eyes, can,...  35.000000  \n",
       "3    [bangs, black_hair, blue_eyes, blush, breasts,...  16.666667  \n",
       "4    [:/, :d, :o, blush, braided_ponytail, closed_e...  47.619048  \n",
       "..                                                 ...        ...  \n",
       "145  [!!, :d, blue_hair, brown_eyes, collared_shirt...  13.043478  \n",
       "146  [bag, bags_under_eyes, black_hair, blue_eyes, ...  41.176471  \n",
       "147  [5girls, aqua_hair, black_eyes, blue_eyes, blu...  29.629630  \n",
       "148  [:d, :o, arrow_(projectile), black_shirt, blon...  27.272727  \n",
       "149  [blonde_hair, blush, breasts, chibi, eyebrows_...  61.111111  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = evaluated_data['train'].to_pandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.618037296233258"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
