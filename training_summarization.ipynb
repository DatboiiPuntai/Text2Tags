{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "!pip install -q bitsandbytes datasets accelerate loralib sentencepiece\n",
    "!pip install tensorboardX\n",
    "!pip install -q git+https://github.com/huggingface/transformers.git git+https://github.com/huggingface/peft.git"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (None)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda117.dll\n",
      "CUDA SETUP: CUDA runtime path found: C:\\Users\\panta\\anaconda3\\envs\\nlp\\bin\\cudart64_110.dll\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda117.dll...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:152: UserWarning: C:\\Users\\panta\\anaconda3\\envs\\nlp did not contain ['cudart64_110.dll', 'cudart64_120.dll'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:152: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {WindowsPath('C:/Users/panta/anaconda3/envs/nlp/Library/usr/bin'), WindowsPath('C:/Users/panta/anaconda3/envs/nlp/Library/mingw-w64/bin')}\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_int8_training\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL = \"google/flan-t5-small\"\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    # load_in_8bit=True,\n",
    "    # torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 688128 || all params: 77649280 || trainable%: 0.8862001038515747\n"
     ]
    }
   ],
   "source": [
    "# model = prepare_model_for_int8_training(model)\n",
    "# config = LoraConfig(\n",
    "#     r=16,\n",
    "#     lora_alpha=32,\n",
    "#     target_modules=[\"q\", \"v\"],\n",
    "#     lora_dropout=0.05,\n",
    "#     bias=\"none\",\n",
    "#     task_type=\"SEQ_2_SEQ_LM\",\n",
    "# )\n",
    "# model = get_peft_model(model, config)\n",
    "# model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/panta/.cache/huggingface/datasets/json/default-fac367448397b4f6/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f8a1095a514189be657f5a96a51ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['caption_string', 'tag_string'],\n",
       "        num_rows: 19950\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"json\", data_files=r'dataset/train_data.json')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"summarize: \"\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"caption_string\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "    labels = tokenizer(\n",
    "        text_target=examples[\"tag_string\"], max_length=1024, truncation=True\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at C:\\Users\\panta\\.cache\\huggingface\\datasets\\json\\default-fac367448397b4f6\\0.0.0\\fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\\cache-a753b907c50531b5.arrow and C:\\Users\\panta\\.cache\\huggingface\\datasets\\json\\default-fac367448397b4f6\\0.0.0\\fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\\cache-402f08e87db1eb6b.arrow\n",
      "Loading cached processed dataset at C:\\Users\\panta\\.cache\\huggingface\\datasets\\json\\default-fac367448397b4f6\\0.0.0\\fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\\cache-f45342928e41ed12.arrow\n",
      "Loading cached processed dataset at C:\\Users\\panta\\.cache\\huggingface\\datasets\\json\\default-fac367448397b4f6\\0.0.0\\fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\\cache-47cef8e61ebab212.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['caption_string', 'tag_string', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 18952\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['caption_string', 'tag_string', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 998\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_data = data[\"train\"].train_test_split(test_size=0.05, shuffle=True, seed=42)\n",
    "tokenized_data = split_data.map(preprocess_function, batched=True)\n",
    "tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "label_pad_token_id = -100\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=label_pad_token_id,\n",
    "    pad_to_multiple_of=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"outputs/flan-t5\",\n",
    "    auto_find_batch_size=True,\n",
    "    learning_rate=3e-4,\n",
    "    num_train_epochs=5,\n",
    "    predict_with_generate=True,\n",
    "    metric_for_best_model=\"f1_weighted\",\n",
    "    load_best_model_at_end=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    report_to=\"tensorboard\",\n",
    "    fp16=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiLabelBinarizer(classes=[&#x27;1girl&#x27;, &#x27;solo&#x27;, &#x27;long_hair&#x27;, &#x27;breasts&#x27;, &#x27;blush&#x27;,\n",
       "                             &#x27;looking_at_viewer&#x27;, &#x27;smile&#x27;, &#x27;short_hair&#x27;,\n",
       "                             &#x27;open_mouth&#x27;, &#x27;bangs&#x27;, &#x27;blue_eyes&#x27;,\n",
       "                             &#x27;multiple_girls&#x27;, &#x27;blonde_hair&#x27;, &#x27;skirt&#x27;,\n",
       "                             &#x27;brown_hair&#x27;, &#x27;large_breasts&#x27;, &#x27;simple_background&#x27;,\n",
       "                             &#x27;black_hair&#x27;, &#x27;eyebrows_visible_through_hair&#x27;,\n",
       "                             &#x27;thighhighs&#x27;, &#x27;hair_ornament&#x27;, &#x27;hat&#x27;, &#x27;red_eyes&#x27;,\n",
       "                             &#x27;gloves&#x27;, &#x27;shirt&#x27;, &#x27;touhou&#x27;, &#x27;1boy&#x27;, &#x27;dress&#x27;,\n",
       "                             &#x27;white_background&#x27;, &#x27;original&#x27;, ...])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiLabelBinarizer</label><div class=\"sk-toggleable__content\"><pre>MultiLabelBinarizer(classes=[&#x27;1girl&#x27;, &#x27;solo&#x27;, &#x27;long_hair&#x27;, &#x27;breasts&#x27;, &#x27;blush&#x27;,\n",
       "                             &#x27;looking_at_viewer&#x27;, &#x27;smile&#x27;, &#x27;short_hair&#x27;,\n",
       "                             &#x27;open_mouth&#x27;, &#x27;bangs&#x27;, &#x27;blue_eyes&#x27;,\n",
       "                             &#x27;multiple_girls&#x27;, &#x27;blonde_hair&#x27;, &#x27;skirt&#x27;,\n",
       "                             &#x27;brown_hair&#x27;, &#x27;large_breasts&#x27;, &#x27;simple_background&#x27;,\n",
       "                             &#x27;black_hair&#x27;, &#x27;eyebrows_visible_through_hair&#x27;,\n",
       "                             &#x27;thighhighs&#x27;, &#x27;hair_ornament&#x27;, &#x27;hat&#x27;, &#x27;red_eyes&#x27;,\n",
       "                             &#x27;gloves&#x27;, &#x27;shirt&#x27;, &#x27;touhou&#x27;, &#x27;1boy&#x27;, &#x27;dress&#x27;,\n",
       "                             &#x27;white_background&#x27;, &#x27;original&#x27;, ...])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiLabelBinarizer(classes=['1girl', 'solo', 'long_hair', 'breasts', 'blush',\n",
       "                             'looking_at_viewer', 'smile', 'short_hair',\n",
       "                             'open_mouth', 'bangs', 'blue_eyes',\n",
       "                             'multiple_girls', 'blonde_hair', 'skirt',\n",
       "                             'brown_hair', 'large_breasts', 'simple_background',\n",
       "                             'black_hair', 'eyebrows_visible_through_hair',\n",
       "                             'thighhighs', 'hair_ornament', 'hat', 'red_eyes',\n",
       "                             'gloves', 'shirt', 'touhou', '1boy', 'dress',\n",
       "                             'white_background', 'original', ...])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "tag_list = open(r'dictionaries/tag_dict.txt').read().splitlines()\n",
    "mlb = MultiLabelBinarizer(classes=tag_list)\n",
    "mlb.fit([list(tag_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "from utils import similar_tag\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)[0]\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)[0]\n",
    "\n",
    "    pred_tags = [x.strip() for x in decoded_preds.split(\",\")]\n",
    "    pred_tags_corrected = similar_tag.correct_tags(pred_tags, tag_list)\n",
    "\n",
    "    tags = [x.strip() for x in decoded_labels.split(\",\")]\n",
    "\n",
    "    one_hots_pred = mlb.transform([pred_tags_corrected])\n",
    "    one_hots_truth = mlb.transform([tags])\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    accuracy = accuracy_score(y_true=one_hots_truth, y_pred=one_hots_pred)\n",
    "    recall = recall_score(\n",
    "        y_true=one_hots_truth, y_pred=one_hots_pred, average=\"weighted\", zero_division=1\n",
    "    )\n",
    "    precision = precision_score(\n",
    "        y_true=one_hots_truth, y_pred=one_hots_pred, average=\"weighted\", zero_division=1\n",
    "    )\n",
    "    f1_micro = f1_score(\n",
    "        y_true=one_hots_truth, y_pred=one_hots_pred, average=\"micro\", zero_division=1\n",
    "    )\n",
    "    f1_macro = f1_score(\n",
    "        y_true=one_hots_truth, y_pred=one_hots_pred, average=\"macro\", zero_division=1\n",
    "    )\n",
    "    f1_weighted = f1_score(\n",
    "        y_true=one_hots_truth, y_pred=one_hots_pred, average=\"weighted\", zero_division=1\n",
    "    )\n",
    "\n",
    "    results[\"accuracy\"] = accuracy\n",
    "    results[\"recall\"] = recall\n",
    "    results[\"precision\"] = precision\n",
    "    results[\"f1_micro\"] = f1_micro\n",
    "    results[\"f1_macro\"] = f1_macro\n",
    "    results[\"f1_weighted\"] = f1_weighted\n",
    "\n",
    "    return {k: round(v, 4) for k, v in results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[transformers.EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89238f45886b452e902005b94683de6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11845 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4054, 'learning_rate': 0.0002873364288729421, 'epoch': 0.21}\n",
      "{'loss': 1.968, 'learning_rate': 0.0002746728577458843, 'epoch': 0.42}\n",
      "{'loss': 1.8148, 'learning_rate': 0.0002620092866188265, 'epoch': 0.63}\n",
      "{'loss': 1.7189, 'learning_rate': 0.00024934571549176863, 'epoch': 0.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\transformers\\generation\\utils.py:1250: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0ca9d57e854863a7a2047dada933a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 11389)\n",
      "{'eval_loss': 1.340453863143921, 'eval_accuracy': 0.0, 'eval_recall': 0.0882, 'eval_precision': 1.0, 'eval_f1_micro': 0.1579, 'eval_f1_macro': 0.9972, 'eval_f1_weighted': 0.0882, 'eval_runtime': 218.6781, 'eval_samples_per_second': 4.564, 'eval_steps_per_second': 0.572, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\panta\\anaconda3\\envs\\nlp\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6581, 'learning_rate': 0.00023668214436471083, 'epoch': 1.06}\n",
      "{'loss': 1.5984, 'learning_rate': 0.000224018573237653, 'epoch': 1.27}\n",
      "{'loss': 1.5491, 'learning_rate': 0.00021135500211059518, 'epoch': 1.48}\n",
      "{'loss': 1.5106, 'learning_rate': 0.00019869143098353735, 'epoch': 1.69}\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"summarize: Minato aqua, the hololive vtuber wearing a deep blue maid outfit with maid cap with pink and blue streaked hair styled in twintails\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = transformers.pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
    "summarizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.push_to_hub(\"ooferdoodles/text2tags-opt-350m\", use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(r\"loras/tagger-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
